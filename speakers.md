---
layout: page
title: Speakers
subtitle: 
---


<div class='row'>

  <div class="col-3">

    <div class="frame">

      <img class="speaker-img" src='/assets/img/michael.jpg'>

    </div>

  </div>

  <div class="col-9">

    <h4> <a href="https://scholars.duke.edu/person/michael.tomasello" target="_blank"> Michael Tomasello </a></h4>

    <p class='speaker-affiliation'> University of Duke </p>

      <p style='font-size: 11pt;'>

        <b>Talk title: </b>  Agency and Cognitive Development

    </p>
    <button type="button" class="collapsible">Bio</button>
    <div class="content">
        <p style='margin-top: 5pt;font-size: 11pt;'>
        Michael Tomasello is Professor of Psychology and Neuroscience at Duke University and emeritus Director of the Max Planck Institute for Evolutionary Anthropology, Leipzig, Germany.  His research interests focus on processes of social cognition, social learning, and communication/language in human children and great apes. </p>
    </div>
    <button type="button" class="collapsible">Abstract</button>
    <div class="content">
        <p style='margin-top: 5pt;font-size: 11pt;'>
        Modern theories explain children’s cognitive development mainly in term of Bayesian learning (with some innate priors in infancy). But learning cannot be the whole story or else children could learn anything at any age - which they cannot. They cannot because their capacities to experience and cognitively represent the world are structured by the human species’ evolved psychological architecture - inherited from ancient animal ancestors - and this architecture changes in significant ways over the first years of life. The main organizing principle is agency, including shared agency. The developmental proposal is that young infants (below 9 months) are goal-directed agents who cognitively represent and learn about actualities; toddlers are intentional agents who executively represent and learn also about causal, intentional, and logical possibilities; and preschoolers (over 3 years) are metacognitive agents who metacognitively represent and learn also about normative necessities. This agency-based model of cognitive development recognizes the important role of learning, but at the same time places it in the context of the overall agentive organization of children at particular developmental periods.
        </p>
    </div>

  </div>
</div>


<div class='row'>

  <div class="col-3">

    <div class="frame">

      <img class="speaker-img" src='/assets/img/georg.jpg'>

    </div>

  </div>

  <div class="col-9">

    <h4> <a href="https://is.mpg.de/en/people/gmartius" target="_blank"> Georg Martius </a></h4>

    <p class='speaker-affiliation'> Max Planck Institute for Intelligent Systems, University of Tübingen</p>

      <p style='font-size: 11pt;'>

        <b>Talk title: </b>  Intrinsic Motivations for Efficient Exploration in Reinforcement Learning

    </p>
    <button type="button" class="collapsible">Bio</button>
    <div class="content">
        <p style='margin-top: 5pt;font-size: 11pt;'>
        Georg Martius is a full professor at the University of Tübingen in Computer Science since 2023. He is also leading a research group on Autonomous Learning at the Max Planck Institute for Intelligent Systems in Tübingen. Before joining the MPI in Tübingen, he was a postdoc fellow at the IST Austria and was a postdoctoral researcher at the Max Planck Institute for Mathematics in the Sciences in Leipzig. He received his Ph.D. from the University of Göttingen and his computer science degree from University of Leipzig. His research focus is on machine learning for robotics, including internal model learning, reinforcement learning, intrinsic motivations, representation learning, differentiable combinatorial optimization and haptics.
        </p>    
    </div>

    <button type="button" class="collapsible">Abstract</button>
    <div class="content">
        <p style='margin-top: 5pt;font-size: 11pt;'>
        I will summarize research in the area of intrinsic motivation in the context of learning and exploration and touch upon open-ended learning in the IMOL community. I will then present our recent work on combining different intrinsic motivation signals with reinforcement learning, such as learning progress, causal influence and information gain. A particular exciting direction is to employ model-based reinforcement learning to make robots learn by freely playing how to interact effectively driven by information gain and other generic drives. We find that this leads to high zero-shot generalization to new tasks.
        </p>
    </div>
  </div>
</div>

<div class='row'>

  <div class="col-3">

    <div class="frame">

      <img class="speaker-img" src='/assets/img/natalia.png'>

    </div>

  </div>

  <div class="col-9">

    <h4> <a href="https://nataliavelez.org/" target="_blank"> Natalia Vélez </a></h4>

    <p class='speaker-affiliation'> Princeton </p>

      <p style='font-size: 11pt;'>

        <b>Talk title: </b> How Do Humans Overcome Individual Computational Limitations by Working Together?

    </p>
    <button type="button" class="collapsible">Bio</button>
    <div class="content">
        <p style='margin-top: 5pt;font-size: 11pt;'>
I am an assistant professor in the Department of Psychology at Princeton University. My lab studies the cognitive capacities and community dynamics that make human collaboration possible. We approach collaboration at two levels of analysis. Zooming in, our work seeks to understand how individuals navigate collaborations—that is, how individuals learn about their collaborators, share knowledge with one another, and divide labor. Zooming out, our work examines how community-wide dynamics contribute to the success of collaborations. Outside of the lab, I draw <a href="https://nataliavelez.org/sketches/"> portraits </a> of scientists alongside their science.         </p>    
    </div>

    <button type="button" class="collapsible">Abstract</button>
    <div class="content">
        <p style='margin-top: 5pt;font-size: 11pt;'>
        TBD
        </p>
    </div>
  </div>
</div>

<div class='row'>

  <div class="col-3">

    <div class="frame">

      <img class="speaker-img" src='/assets/img/jurgen.jpeg'>

    </div>

  </div>
  <div class="col-9">

    <h4> <a href="https://people.idsia.ch/~juergen/" target="_blank"> Jürgen Schmidhuber </a></h4>
    <p class='speaker-affiliation'> KAUST, AI Swiss Lab </p>
      <p style='font-size: 11pt;'>
        <b>Talk title: </b> Artificial Neural Nets with Intrinsic Motivation Since 1990
    </p>
    <button type="button" class="collapsible">Bio</button>
    <div class="content">
        <p style='margin-top: 5pt;font-size: 11pt;'>
The New York Times headlined: "When A.I. Matures, It May Call Jürgen Schmidhuber 'Dad'." Since age 15, his main goal has been to build a self-improving A.I. smarter than himself, then retire. His lab's deep learning artificial neural networks based on ideas published in the "Annus Mirabilis" 1990-1991 have revolutionised machine learning and A.I. By 2017, they were on over 3 billion smartphones, and used billions of times per day, for Facebook’s automatic translation, Google’s speech recognition, Google Translate, Apple’s Siri & QuickType, Amazon’s Alexa, etc. He pioneered generative adversarial networks (1990, now widely used), artificial curiosity, Transformers with linearized self-attention (1991 - Transformers are the basis of the famous ChatGPT), and meta-learning machines that learn to learn (since 1987). Today, the most cited neural networks all build on work done in his labs. He is recipient of numerous awards, Director of the AI Initiative at KAUST in KSA, Scientific Director of the Swiss AI Lab IDSIA, Adj. Prof. of A.I. at Univ. Lugano, and Co-Founder & Chief Scientist of the company NNAISENSE. He is a frequent keynote speaker at major events, and advising various governments on A.I. strategies.
        </p>
    </div>

    <button type="button" class="collapsible">Abstract</button>
    <div class="content">
        <p style='margin-top: 5pt;font-size: 11pt;'>
        Artificial Neural Nets with Intrinsic Motivation Since 1990.
For over three decades I have published work about artificial scientists equipped with intrinsic motivation to implement artificial curiosity and creativity. In this context, I have frequently pointed out that there are two important things in science: (A) Finding answers to given questions, and (B) Coming up with good questions. (A) is arguably just the standard problem of computer science. But how to implement the creative part (B) in artificial systems through reinforcement learning (RL), gradient-based artificial neural networks (NNs), and other machine learning methods? Here I summarise some of our approaches:
<ul style='font-size: 11pt;'>
<li>1990: Intrinsic motivation through the principle of generative adversarial NNs</li>
<li>1991: Intrinsic motivation through NNs that maximise learning progress</li>
<li>1995: RL to maximise information gain or Bayesian surprise. (2011: Do this optimally)</li>
<li>1997: Adversarial RL agents design surprising computational experiments</li>
<li>2022: NNs generating complex experiments encoded as NN weight matrices</li>
<li>2006: Intrinsic motivation to maximise compression progress like scientists/artists/comedians do</li>
<li>2011: Intrinsic Motivation through PowerPlay which continually searches for novel well-defined computational problems whose solutions can easily be added to the skill repertoire, taking into account verification time</li>
<li>2015: Planning and intrinsic motivation with spatio-temporal abstractions in NNs</li>
</ul>    
</p>
    </div>
  </div>
</div>


<div class='row'>

  <div class="col-3">

    <div class="frame">

      <img class="speaker-img" src='/assets/img/dani.jpeg'>

    </div>

  </div>

  <div class="col-9">

    <h4> <a href="https://complexsystemsupenn.com/personal" target="_blank"> Dani S. Bassett </a></h4>

    <p class='speaker-affiliation'> University of Pennsylvania </p>

      <p style='font-size: 11pt;'>

        <b>Talk title: </b>  Agents of Curiosity: Testing Network Theories in Human and Non-Human Inquirers

    </p>
    <button type="button" class="collapsible">Bio</button>
    <div class="content">
        <p style='margin-top: 5pt;font-size: 11pt;'>
Prof. Bassett is the J. Peter Skirkanich Professor at the University of Pennsylvania, with appointments in the Departments of Bioengineering, Electrical & Systems Engineering, Physics & Astronomy, Neurology, and Psychiatry. They are also an external professor of the Santa Fe Institute. Bassett is most well-known for blending neural and systems engineering to identify fundamental mechanisms of cognition and disease in human brain networks. They received a B.S. in physics from Penn State University and a Ph.D. in physics from the University of Cambridge, UK as a Churchill Scholar, and as an NIH Health Sciences Scholar. Following a postdoctoral position at UC Santa Barbara, Bassett was a Junior Research Fellow at the Sage Center for the Study of the Mind. They have received multiple prestigious awards, including American Psychological Association's ‘Rising Star’ (2012), Alfred P Sloan Research Fellow (2014), MacArthur Fellow Genius Grant (2014), Early Academic Achievement Award from the IEEE Engineering in Medicine and Biology Society (2015), Office of Naval Research Young Investigator (2015), National Science Foundation CAREER (2016), Popular Science Brilliant 10 (2016), Lagrange Prize in Complex Systems Science (2017), Erdos-Renyi Prize in Network Science (2018), OHBM Young Investigator Award (2020), AIMBE College of Fellows (2020), American Physical Society Fellow (2021), and has been named one of Web of Science's most Highly Cited Researchers for 3 years running. Bassett is the author of more than 400 peer-reviewed publications, which have garnered over 45,000 citations, as well as numerous book chapters and teaching materials. Bassett’s work has been supported by the National Science Foundation, the National Institutes of Health, the Army Research Office, the Army Research Laboratory, the Office of Naval Research, the Department of Defense, the Alfred P Sloan Foundation, the John D and Catherine T MacArthur Foundation, the Paul Allen Foundation, the ISI Foundation, and the Center for Curiosity. Bassett has recently co-authored Curious Minds: The Power of Connection (MIT Press) with philosopher and twin Perry Zurn.
        </p>
    </div>

    <button type="button" class="collapsible">Abstract</button>
    <div class="content">
        <p style='margin-top: 5pt;font-size: 11pt;'>
        TBD
        </p>
    </div>
  </div>
</div>


<div class='row'>

  <div class="col-3">

    <div class="frame">

      <img class="speaker-img" src='/assets/img/doina.jpeg'>

    </div>

  </div>

  <div class="col-9">

    <h4> <a href="https://rl.cs.mcgill.ca/people/doina-precup" target="_blank"> Doina Precup </a></h4>

    <p class='speaker-affiliation'> McGill University, Mila, Google DeepMind </p>

      <p style='font-size: 11pt;'>

        <b>Talk title: </b>  TBD

    </p>
    <button type="button" class="collapsible">Bio</button>
    <div class="content">
        <p style='margin-top: 5pt;font-size: 11pt;'>
Doina Precup splits her time between McGill University, where she holds a Canada-CIFAR AI chair, and Google DeepMind where she has been leading the Montreal research team since 
its formation in October 2017 and the Deep Reinforcement Learning team since 2021. She is also a core member of Mila (the Quebec AI institute) and a Fellow of the Royal Society 
of Canada, noted for her fundamental contributions to reinforcement learning. Dr. Precup obtained her Ph.D. in Computer Science at the University of Massachusetts-Amherst in 2000. Her main research interests are in reinforcement learning, especially neverending learning and making deep RL more efficient and real-world applications of machine learning, with an emphasis on medicine. Dr. Precup is also involved in activities aiming to improve diversity in machine learning.
        </p>
    </div>

    <button type="button" class="collapsible">Abstract</button>
    <div class="content">
        <p style='margin-top: 5pt;font-size: 11pt;'>
        TBD
        </p>
    </div>
  </div>
</div>

<div class='row'>

  <div class="col-3">

    <div class="frame">

      <img class="speaker-img" src='/assets/img/feryal.png'>

    </div>

  </div>

  <div class="col-9">

    <h4> <a href="https://feryal.github.io/" target="_blank"> Feryal Behbahani </a></h4>

    <p class='speaker-affiliation'> Google DeepMind </p>

      <p style='font-size: 11pt;'>

        <b>Talk title: </b>  TBD

    </p>


    <button type="button" class="collapsible">Abstract</button>
    <div class="content">
        <p style='margin-top: 5pt;font-size: 11pt;'>
        TBD
        </p>
    </div>
  </div>
</div>




